{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "MLH Localhost Emoji Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhNsmmwYhmq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYVpcYZKiHFw",
        "colab_type": "code",
        "outputId": "121adb8c-88e5-4272-d51f-5400cb06f46e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvvHG0haiKP7",
        "colab_type": "code",
        "outputId": "06411c24-5808-4712-f19e-521caca268f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "path = 'gdrive/My Drive/Colab Notebooks/EmojiPredictionDataset/'\n",
        "path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gdrive/My Drive/Colab Notebooks/EmojiPredictionDataset/'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjQ7fl8GhvuF",
        "colab_type": "text"
      },
      "source": [
        "**Numpy**\n",
        "1.   NumPy is the fundamental package for scientific computing with Python.\n",
        "2.   It provides a high-performance multidimensional array object, and tools for    working with these arrays.\n",
        "\n",
        "**Pandas**\n",
        "\n",
        "\n",
        "1.   Pandas is the most popular python library that is used for data analysis.\n",
        "2.   We can manipulate like Excel sheets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47SPtpp3hu89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBY1G42jTrrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the traning data\n",
        "train_data = pd.read_csv(\"Train.csv\")\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1h69wAGTrrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the testing data\n",
        "test_data = pd.read_csv(\"Test.csv\")\n",
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAPkSBZoTrrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the mappings file\n",
        "mappings = pd.read_csv(\"Mapping.csv\")\n",
        "mappings.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrnUDYs0TrrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the shapes of all files\n",
        "train_data.shape, test_data.shape, mappings.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6cyWe5_TrrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_length = train_data.shape[0]\n",
        "test_length = test_data.shape[0]\n",
        "train_length, test_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aezZcOx5hGE_",
        "colab_type": "text"
      },
      "source": [
        "**NLTK is a library for Natural Language Processing (NLP) to create features from text**\n",
        "When using words as features, we need to handle:\n",
        "1.   Context -> eg: Not good\n",
        "2.   Identify root words -> eg: help, helper, helping\n",
        "3.   Words with similar meaning -> eg: good and nice\n",
        "\n",
        "**Stopwords are useless words or commonly used words. They add very little information to our model so can be removed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B_k7tb7iwIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWbIXyLpTrrX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stop_words[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ne4Sp9CEjj8Y",
        "colab_type": "text"
      },
      "source": [
        "We need to follow the following steps to pre process the data before using it:\n",
        "\n",
        "\n",
        "1.   Each tweet should be tokenized into a list of words\n",
        "2.   Remove words starting with **@** because they generally refer to twitter       handles and thus provide little or no information\n",
        "3.   Remove **stopwords**\n",
        "4.   Remove the **#** character to get the actual word used as hashtag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9fktDcETrrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the sentences\n",
        "def tokenize(tweets):\n",
        "    stop_words = stopwords.words(\"english\")\n",
        "    tokenized_tweets = []\n",
        "    for tweet in tweets:\n",
        "        # split all words in the tweet\n",
        "        words = tweet.split(\" \")\n",
        "        tokenized_string = \"\"\n",
        "        for word in words:\n",
        "            # remove @handles -> useless -> no information\n",
        "            if word[0] != '@' and word not in stop_words:\n",
        "                # if a hashtag, remove # -> adds no new information\n",
        "                if word[0] == \"#\":\n",
        "                    word = word[1:]\n",
        "                tokenized_string += word + \" \"\n",
        "        tokenized_tweets.append(tokenized_string)\n",
        "    return tokenized_tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAWVuUB5kTgt",
        "colab_type": "text"
      },
      "source": [
        "**Keras** - It is an Open Source Neural Network library written in Python that runs on top of Tensorflow, i.e., it uses tensors to run the operations. \n",
        "\n",
        "**Tokenizer** - vectorize text by turning each text into a sequence of integers\n",
        "\n",
        "**filters** - a string where each element is a character that will be filtered from text\n",
        "\n",
        "**lower** - boolean for lower case conversion\n",
        "\n",
        "**tokenizer.texts_to_sequences(tweets)** - transform each tweet in tweets to a sequence of integers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Tv-GcMk-BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDYKYpogTrrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# translate tweets to a sequence of numbers\n",
        "def encod_tweets(tweets):\n",
        "    tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', split=\" \", lower=True)\n",
        "    tokenizer.fit_on_texts(tweets)\n",
        "    return tokenizer, tokenizer.texts_to_sequences(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHSNYPIAnIzy",
        "colab_type": "text"
      },
      "source": [
        "**Example**  \n",
        "Uncomment and run the following code cell to see the example of the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCoLHwgbnFWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example_str = tokenize(['This is a good day. @css #mlhlocalhost'])\n",
        "# encod_str = encod_tweets(example_str)\n",
        "# print(example_str)\n",
        "# print(encod_str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5f86grjnQrh",
        "colab_type": "text"
      },
      "source": [
        "**pad_sequences** - transforms list of sequences (list of integers) into 2D numpy arrays of shape (num_samples, maxlen)\n",
        "\n",
        "maxlen is the length of longest sequence, can be provided as an argument also\n",
        "\n",
        "If sequences are shorter than maxlen, they are padded with value at front or end (pre or post padding)\n",
        "If sequences are longer than maxlen, they are truncated\n",
        "\n",
        "**bit_vec** -> vector of 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfXG5OpcnSr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e_9WxxrTrre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply padding to dataset and convert labels to bitmaps\n",
        "def format_data(encoded_tweets, max_length, labels):\n",
        "    x = pad_sequences(encoded_tweets, maxlen= max_length, padding='post')\n",
        "    y = []\n",
        "    for emoji in labels:\n",
        "        bit_vec = np.zeros(20)\n",
        "        bit_vec[emoji] = 1\n",
        "        y.append(bit_vec)\n",
        "    y = np.asarray(y)\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBmdEZsITrrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create weight matrix from pre trained embeddings\n",
        "def create_weight_matrix(vocab, raw_embeddings):\n",
        "    vocab_size = len(vocab) + 1\n",
        "    weight_matrix = np.zeros((vocab_size, 300))\n",
        "    for word, idx in vocab.items():\n",
        "        if word in raw_embeddings:\n",
        "            weight_matrix[idx] = raw_embeddings[word]\n",
        "    return weight_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHacZbuhoZa0",
        "colab_type": "text"
      },
      "source": [
        "**Embeddings** -> are used mainly for text processing.\n",
        "\n",
        "**Example**:\n",
        "\n",
        "Hope to see you soon. -> [0, 1, 2, 3, 4] (embedding of words)\n",
        "\n",
        "Nice to see you again. -> [5, 1, 2, 3, 6]\n",
        "\n",
        "**Vocab size** = number of unique words in vocabulary = max number in embeddings + 1 = 6 + 1 = 7\n",
        "\n",
        "**Sequential** -> means we are using linear stack of layers\n",
        "\n",
        "**LSTM** -> Long Short term memory\n",
        "\n",
        "**Bidirectional** -> wrapper to indicate the type of LSTM used\n",
        "\n",
        "**Dense** -> Denselu connected neural network\n",
        "\n",
        "**Activation function** -> decided whether a neuron should be activated or not by calculating weighted sum and adding bias to it.\n",
        "\n",
        "It provides non-linearlity to output of neuron\n",
        "\n",
        "**A neural network without an activation function is just a Linear Regression**. By using activation function, we can make our model solve complex functions.\n",
        "\n",
        "**Softmax** -> similar to **Sigmoid function** -> used for multiple classes, gives output between 0 & 1 and divide by sum of outputs\n",
        "\n",
        "**Optimizer** -> finds the trainable variables on which cost depends and change their values to **optimize cost**\n",
        "\n",
        "**Entroy** -> -sum(p log p) -> avg amount of information drawn from one sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vXGGe1SoNMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njph29eeTrrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# final model\n",
        "def final_model(weight_matrix, vocab_size, max_length, x, y):\n",
        "    embedding_layer = Embedding(vocab_size, 300, weights=[weight_matrix], input_length=max_length, trainable=True, mask_zero=True)\n",
        "    model = Sequential()\n",
        "    model.add(embedding_layer)\n",
        "    model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(128, dropout=0.2)))\n",
        "    model.add(Dense(20, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(x, y, epochs = 1, validation_split = 0.25)\n",
        "    score, acc = model.evaluate(x_test, y_test)\n",
        "    return model, score, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GUdPLfGqfrF",
        "colab_type": "text"
      },
      "source": [
        "Tokenizing the train and test tweets and then encoding them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "p1ih7cnaTrrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_tweets = tokenize(train_data['TEXT'])\n",
        "tokenized_tweets += tokenize(test_data['TEXT'])\n",
        "max_length = math.ceil(sum([len(s.split(\" \")) for s in tokenized_tweets])/len(tokenized_tweets))\n",
        "tokenizer, encoded_tweets = encod_tweets(tokenized_tweets)\n",
        "max_length, len(tokenized_tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CesxAbv6qr86",
        "colab_type": "text"
      },
      "source": [
        "Apply padding to the encoded data using pad_sequences for both train and test tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz-VVuNyTrrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = format_data(encoded_tweets[:train_length], max_length, train_data['Label'])\n",
        "len(x), len(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB_NCYEUTrrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test, y_test = format_data(encoded_tweets[train_length:], max_length, test_data['Label'])\n",
        "len(x_test), len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CsZifURqyf3",
        "colab_type": "text"
      },
      "source": [
        "Building vocabulary using **word_index** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di0js2a-Trru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = tokenizer.word_index\n",
        "vocab[:10], len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FJXLuDurKsa",
        "colab_type": "text"
      },
      "source": [
        "**keyedvectors** -> word vector storage and look up\n",
        "\n",
        "It is used to load hidden weight matrix\n",
        "\n",
        "**binary** -> to specify whether the data is binary or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1FqanFntJMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0zWG0JCTrrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_embeddings = KeyedVectors.load_word2vec_format('model_swm_300-6-10-low.w2v', binary=False)\n",
        "raw_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0CZtO-OrqCX",
        "colab_type": "text"
      },
      "source": [
        "create the weight matrix using our vocab and raw_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAg0GGQvTrrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_matrix = create_weight_matrix(vocab, raw_embeddings)\n",
        "len(weight_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3AokFXWrj0e",
        "colab_type": "text"
      },
      "source": [
        "Run the final model on train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBIHLOvhTrr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, score, acc = final_model(weight_matrix, len(vocab)+1, max_length, x, y)\n",
        "model, score, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rox5OILbTrr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRdcSmJXr0JU",
        "colab_type": "text"
      },
      "source": [
        "Use .predict() funtion to predict the y values for x_test\n",
        "\n",
        "y values are numpy arrays of length 20 == number of classes\n",
        "\n",
        "The class can be found out by finding the index of the maximum value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-ikvcnTrr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy53J1lrTrsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for pred in y_pred:\n",
        "    print(np.argmax(pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5ECDT3isMbL",
        "colab_type": "text"
      },
      "source": [
        "Print the classification report which gives:\n",
        "\n",
        "**precision** -> what % of predicted a's are actually a\n",
        "\n",
        "**recall** -> what % of a are predicted to be a\n",
        "\n",
        "**fi-score** -> Harmonic mean of precision and recall\n",
        "\n",
        "**support** -> actual values of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7qvNXyKtAA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfCCF_Q1TrsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.array([np.argmax(pred) for pred in y_pred])\n",
        "y_true = np.array(test_data['Label'])\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sOTbJsVTrsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emoji_pred = [mappings[mappings['number'] == pred]['emoticons'] for pred in y_pred]\n",
        "emoji_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynMMnnGfTrsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100, 150):\n",
        "    test_tweet = test_data['TEXT'][i]\n",
        "    pred_label = y_pred[i]\n",
        "    pred_emoji = emoji_pred[i]\n",
        "    print('tweet: ', test_tweet)\n",
        "    print('pred emoji: ', pred_label, pred_emoji)\n",
        "    print('-'*50)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}